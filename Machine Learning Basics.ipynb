{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DSL_logo](dsl_logo.png)\n",
    "\n",
    "# Introduction to Machine Learning with Python\n",
    "\n",
    "\n",
    "In [part 2](https://brockdsl.github.io/Python_2.0_Workshop/) we introduced some data science concepts by looking at some fictional data how people that were sick. In this session we are going to see if we can build a machine learning model to see if we can predict who has the illness based on the answers to some questions. We'll also look at two new examples that try to guess the quality of wine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, a brief recap\n",
    "\n",
    "The following code should look familiar to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the file into a dataframe using the pandas read_csv function\n",
    "data = pd.read_csv(\"https://brockdsl.github.io/Python_2.0_Workshop/canadian_toy_dataset.csv\")\n",
    "\n",
    "#Tell it what our columns are by passing along a list of that information\n",
    "data.columns = [\"city\",\"gender\",\"age\",\"income\",\"ill\"]\n",
    "\n",
    "print(\"Ill or not?\")\n",
    "print(data.groupby(\"ill\")[\"city\"].count())\n",
    "print(\"\\nTotal records:\", len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Basics\n",
    "\n",
    "Don't let the impressive name fool you. Machine learning is more or less the following steps\n",
    "\n",
    "1. Getting your data and cleaning it up\n",
    "1. Identify what parts of your data are **features**\n",
    "1. Identify what is your **target variable** that you'll guess based on your features\n",
    "1. Split your data in **training and testing sets**\n",
    "1. **Train** your model against the training set\n",
    "1. **Validate** your model against the testing set\n",
    "1. ????\n",
    "1. Profit\n",
    "\n",
    "\n",
    "We are going to use the Python library [scikit-learn](https://scikit-learn.org/stable/) and we are going to be doing a [classification](https://en.wikipedia.org/wiki/Statistical_classification) problem.\n",
    "\n",
    "![classification](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "This is the most basic machine learning model you can use. It is considered a [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) method. You create the best [decision tree](https://en.wikipedia.org/wiki/Decision_tree_learning) that you can based on your training data. Here's an example tree that shows your chance of surviving the Titanic disaster.\n",
    "\n",
    "![dtree](https://upload.wikimedia.org/wikipedia/commons/e/eb/Decision_Tree.jpg)\n",
    "\n",
    "``sibsp`` - is the number of spouses or siblings on board\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the Libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This should look familar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#We'll draw a graph later on\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Our 'Machine Learning pieces'\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data ready\n",
    "\n",
    "Now, let's load our data. Our decision tree can only work with numbers, so we'll have to modify the columns of data that are text based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://brockdsl.github.io/Python_2.0_Workshop/canadian_toy_dataset.csv\")\n",
    "data.columns = [\"city\",\"gender\",\"age\",\"income\",\"ill\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw last time the data is fairly clean, we just need to represent it all as numbers instead of text labels. So that means we need to change the columns:\n",
    "\n",
    "\n",
    "- `ill` - instead of a No / Yes label we'll use 0 and 1 instead\n",
    "- `city` - this will break out the column into 8 different columns\n",
    "- `gender` - this will break out the column into 2 different columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Instead of yes/no we'll use a 0 or 1\n",
    "data[\"ill\"].replace({\"No\":0, \"Yes\":1},inplace=True)\n",
    "\n",
    "#We change categorical values into numeric ones using `dummies`\n",
    "data = pd.get_dummies(data, columns=['city','gender'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above shows 5 entries that that come from Montreal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows the last 5 entries in the dataframe that come from Edmonton. \n",
    "\n",
    "\n",
    "Now we are done the most difficult part of the process, understanding the data and getting it ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our data cleaned up, and represented in a way that Scikit will be able to analyze. To be honest the most difficult part of the process is done.\n",
    "\n",
    "We now need to split our columns in two types:\n",
    "- **features** represent the data we use to build our guess\n",
    "- **target variable** the thing our model hopes to guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of the following columns are features, we'll make a list of their names\n",
    "features = [\"age\",\\\n",
    "            \"income\",\\\n",
    "            \"city_Edmonton\",\\\n",
    "            \"city_Halifax\",\\\n",
    "            \"city_Montreal\",\n",
    "            \"city_Ottawa\",\\\n",
    "            \"city_Regina\",\\\n",
    "            \"city_Toronto\",\n",
    "            \"city_Vancouver\",\\\n",
    "            \"city_Waterloo\",\\\n",
    "            \"gender_Female\",\\\n",
    "            \"gender_Male\"]\n",
    "\n",
    "X = data[features]\n",
    "\n",
    "#We want to target the ill column\n",
    "y = data.ill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now breakup our rows of data set into two parts\n",
    "- **training set** this is what is used to build the model\n",
    "- **testing set** this is used to see if our guesses are correct\n",
    "\n",
    "We'll build our decision tree using our training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and test together make up 100% of the data!\n",
    "test_percent = 30\n",
    "train_percent = 100 - test_percent\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0,\n",
    "                                                   random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the interesting part, we build our model, **train** it against the **training set** and see how it **predicts** against the **testing set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "treeClass = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "treeClass = treeClass.fit(X_train,y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = treeClass.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the Model\n",
    "\n",
    "To see how good our machine learning model is we need to see how accurate our predictions are. `Scikit` has built in functions and [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) to do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Making Predictions\n",
    "\n",
    "Not bad. We can use our model to predict a guess for **ill** if we pass along all of the other parameters. Our model only tells us if someone is ill or not. This is directly asking our classification model to give us a prediction based on a pretend record.\n",
    "\n",
    "Since this classifier tells us if someone is ill or someone is not ill, it has two outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ill.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I randomly picked a record in the dataset to test if the prediction is correct. \n",
    "# This is from line: 149120 of the datafile\n",
    "person_x_yes = [\n",
    "        32, #age\n",
    "        82311, #income\n",
    "        1, #city_Edmonton\n",
    "        0, #city_Halifax\n",
    "        0, #city_Montreal\n",
    "        0, #city_Ottawa\n",
    "        0, #city_Regina\n",
    "        0, #city_Toronto\n",
    "        0, #city_Vancouver\n",
    "        0, #city_Waterloo\n",
    "        0, #gender_Female\n",
    "        1, #gender_Male\n",
    "]\n",
    "\n",
    "person_x_yes = pd.DataFrame([person_x_yes],columns=X_test.columns)\n",
    "\n",
    "print(\"Someone who is ill\")\n",
    "print(treeClass.predict_proba(person_x_yes))\n",
    "\n",
    "\n",
    "# I randomly picked a record in the dataset to test if the prediction is correct. \n",
    "# This is from line: 149121 of the datafile\n",
    "person_x_no = [\n",
    "        40, #age\n",
    "        89780, #income\n",
    "        1, #city_Edmonton\n",
    "        0, #city_Halifax\n",
    "        0, #city_Montreal\n",
    "        0, #city_Ottawa\n",
    "        0, #city_Regina\n",
    "        0, #city_Toronto\n",
    "        0, #city_Vancouver\n",
    "        0, #city_Waterloo\n",
    "        1, #gender_Female\n",
    "        0, #gender_Male\n",
    "]\n",
    "\n",
    "person_x_no = pd.DataFrame([person_x_no],columns=X_test.columns)\n",
    "\n",
    "print(\"Someone who was not ill\")\n",
    "#Use the dataframe of our fictional person in our model and get our prediction\n",
    "print(treeClass.predict_proba(person_x_no))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing our Decision Tree\n",
    "\n",
    "If we wanted to we could visualize the decision tree that we get, it will be much more complex than what we see at the top of the page. For example, look at one version of the [tree](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/dtree.txt) that I generated.\n",
    "\n",
    "Not the most useful but we can tell that **income level** is the most important factor to answer the question if the target person is ill or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texttree = tree.export_text(treeClass,feature_names=features)\n",
    "with open(\"dtree.txt\",\"w\") as fout:\n",
    "    fout.write(texttree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters - Testing Set Sizes\n",
    "\n",
    "To make our models run better we can tweak _many, many, many_ different parameters. For example, we can vary the testing data size percentage. We'll try some different values and plot our our accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testing_percents = [1,5,10,20,30,100]\n",
    "accuracy = []\n",
    "training_percents = []\n",
    "\n",
    "for test_ratio in testing_percents:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0,\n",
    "                                                        random_state=10)\n",
    "    treeClassTest = DecisionTreeClassifier()\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    training_percents.append(100 - test_ratio)\n",
    "\n",
    "    \n",
    "plt.plot(training_percents,accuracy)\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Training Size %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your graph might look different, this is a statistical operation and will probably vary across different machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Parameters - Maximum depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 70\n",
    "max_options = [5,10,15,20,25,30]\n",
    "\n",
    "accuracy = []\n",
    "tree_max = []\n",
    "\n",
    "for max_d in max_options:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0,\n",
    "                                                        random_state=10,\n",
    "                                                       )\n",
    "    \n",
    "    #We set maximum depth in the DecisionTreeClassifer when we first create the variable\n",
    "    treeClassTest = DecisionTreeClassifier(max_depth=max_d)\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    tree_max.append(max_depth)\n",
    "\n",
    "    \n",
    "plt.plot(max_options,accuracy)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth of Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "\n",
    "We are going to look at a [cancer survivor data set](http://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival) from the UCI machine learning archive.\n",
    "\n",
    "![cancer_description](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/cancer_characteristics.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cancer_data = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data\",header=None)\n",
    "cancer_data.columns = [\"age\",\"operation_year\",\"pos_nodes\",\"survival_status\"]\n",
    "cancer_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "- What should our features list look like?\n",
    "- What should or target column be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What features list should we use, uncomment the correct answer\n",
    "\n",
    "#cancer_features = [\"age\",\"operation_year\",\"positive_nodes\",\"survival_status\"]\n",
    "#cancer_features = [\"age\",\"operation_year\",\"positive_nodes\"]\n",
    "#cancer_features = [\"age\",\"operation_year\"]\n",
    "#cancer_features = [\"age\"]\n",
    "#cancer_features = [\"operation_year\",\"positive_nodes\",\"survival_status\"]\n",
    "\n",
    "\n",
    "\n",
    "#What target should we use, uncomment the correct answer\n",
    "\n",
    "#cancer_target = cancer_data.age\n",
    "#cancer_target = cancer_data.operation_year\n",
    "#cancer_target = cancer_data.positive_nodes\n",
    "#cancer_target = cancer_data.survival_status\n",
    "\n",
    "X = cancer_data[cancer_features]\n",
    "y = cancer_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll start with 40 just for fun\n",
    "test_percent = 40\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0,\n",
    "                                                   random_state=10)\n",
    "# Create Decision Tree classifer object\n",
    "treeClass = DecisionTreeClassifier(max_depth=max_tree_depth)\n",
    "\n",
    "# Train\n",
    "treeClass = treeClass.fit(X_train,y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = treeClass.predict(X_test)\n",
    "\n",
    "#Accuracy?\n",
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Tuning the testing set size\n",
    "\n",
    "Experiment with adding some values in the `testing_percents` list. In the chat box put in the testing set size that produced the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# put in some values between 0 - 100\n",
    "testing_percents = []\n",
    "\n",
    "\n",
    "accuracy = []\n",
    "training_percents = []\n",
    "\n",
    "for test_ratio in testing_percents:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0,\n",
    "                                                        random_state=10)\n",
    "    treeClassTest = DecisionTreeClassifier()\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    training_percents.append(100 - test_ratio)\n",
    "\n",
    "    \n",
    "plt.plot(training_percents,accuracy)\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Training Size %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Turning Parameters - Maximum Tree Depth\n",
    "\n",
    "\n",
    "Experiment with adding some values in the `max_options` list. In the chat box put in the testing set size that produced the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 30\n",
    "\n",
    "#Put in some options between 1 and 40\n",
    "max_options = []\n",
    "\n",
    "accuracy = []\n",
    "tree_max = []\n",
    "\n",
    "for max_d in max_options:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0,\n",
    "                                                        random_state=10,\n",
    "                                                       )\n",
    "    \n",
    "    #We set maximum depth in the DecisionTreeClassifer when we first create the variable\n",
    "    treeClassTest = DecisionTreeClassifier(max_depth=max_d)\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    tree_max.append(max_depth)\n",
    "\n",
    "    \n",
    "plt.plot(max_options,accuracy)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth of Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "- What is the best combination of `max_depth` and `testing size` that produced the *highest* accuracy?\n",
    "- What is the worst combination of `max_depth` and `testing size` that produced the *lowest* acccuracy? \n",
    "\n",
    "Share your answers in the chat.\n",
    "\n",
    "You can experiment using the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Change the following values\n",
    "test_percent = \n",
    "max_tree_depth = \n",
    "\n",
    "#HINT: You can use the previous graphs to help you pick your values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0,\n",
    "                                                   random_state=10)\n",
    "# Create Decision Tree classifer object\n",
    "treeClass = DecisionTreeClassifier(max_depth=max_tree_depth)\n",
    "\n",
    "# Train\n",
    "treeClass = treeClass.fit(X_train,y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = treeClass.predict(X_test)\n",
    "\n",
    "#Accuracy?\n",
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats!\n",
    "\n",
    "We have just scratched the surface with what is possible with Python and SciKit. Remember, don't let the name **Machine Learning** fool you. Most of the time the computer is making guesses based on past data. Sometimes this works good, sometimes it doesn't work so good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- [UCI Machine Learning Archive](http://archive.ics.uci.edu/ml) A place to find good data sets that you can use to build models with\n",
    "\n",
    "- [A Gentle Introduction to Scikit-Learn](https://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/)\n",
    "\n",
    "- [Data Science Handbook by Field Cady](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119092919)\n",
    "\n",
    "- [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) - A bit more complex, but is a good next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Post Workshop Exercises\n",
    "\n",
    "\n",
    "We'll now try to apply what we know about decision trees. We are going to use a dataset from the [UCI machine learning archive](http://archive.ics.uci.edu/ml/datasets/Wine+Quality). We'll start with the white wine data. This screen capture shows the details of the columns of the data:\n",
    "\n",
    "![wine_columns](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/wine_columns.png)\n",
    "\n",
    "We want to create a classification that guesses the quality of the wine based on the first 11 chemical characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_wine = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",sep=';')\n",
    "white_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features should be in our model? What should our target be? Let's look at our dataframe columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Let's fill in the `white_wine_features` list variable below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in this list\n",
    "white_wine_features = []\n",
    "\n",
    "white_X_features = white_wine[white_wine_features]\n",
    "white_X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 \n",
    "\n",
    "In the chat box describe what our **target** should be.\n",
    "Complete the assignment for `white_target` below once you have an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're looking for the column name\n",
    "white_target = white_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "Try to come up with a good testing percentage size. Share it with everyone else after you've measured your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "white_test_percent = \n",
    "\n",
    "#Split into training testing\n",
    "X_white_train, X_white_test, y_white_train, y_white_test = train_test_split(white_X_features, \\\n",
    "                                                    white_target, \\\n",
    "                                                    test_size=white_test_percent/100.0,\n",
    "                                                   random_state=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!!** You have done the most difficult part of a machine learning task. Understanding the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model and get our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "whiteTree = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "whiteTree = whiteTree.fit(X_white_train,y_white_train)\n",
    "\n",
    "#Predict\n",
    "white_prediction = whiteTree.predict(X_white_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how accurate we are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_white_test,white_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some predictions with this tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From line 1408, 8.2;0.22;0.36;6.8;0.034;12;90;0.9944;3.01;0.38;10.5;8\n",
    "white_x_good = [\n",
    "    8.2, #'fixed acidity'\n",
    "    0.22, #'volatile acidity'\n",
    "    0.36, #'citric acid' \n",
    "    6.8, #'residual sugar'\n",
    "    0.034, #'chlorides'\n",
    "    12, #'free sulfur dioxide'\n",
    "    100, #'total sulfur dioxide'\n",
    "    0.0, #'density'\n",
    "    0.9944, #'pH'\n",
    "    0.038, #'sulphates'\n",
    "    10.5  #'alcohol'\n",
    "]\n",
    "\n",
    "white_x_good = pd.DataFrame([white_x_good],columns=X_white_test.columns)\n",
    "whiteTree.predict_proba(white_x_good)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "The above answer is a list with only 7 options, yet our wine score is from 0-10. Can you come up with why that is the case. Feel free to write you answer in the chat box. \n",
    "\n",
    "If you need a hint, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(white_wine[\"quality\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "One more time!\n",
    "\n",
    "(If we have time together we'll try this, if not please give it a shot on your own) Let's try the red wine data, does the classification work better? What is the best score you can get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",sep=';')\n",
    "red_wine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the next 3 variables and the model will run correctly\n",
    "\n",
    "#Create this list, this will be the same as with the white wine\n",
    "red_features = []\n",
    "\n",
    "#What column do we want to target, this will be the same as with the white wine\n",
    "red_target = red_wine.\n",
    "\n",
    "#What is a good testing percentage\n",
    "red_test_percent =\n",
    "\n",
    "\n",
    "#Build and run our model...\n",
    "red_X_features = red_wine[red_features]\n",
    "\n",
    "#Split into training testing\n",
    "X_red_train, X_red_test, y_red_train, y_red_test = train_test_split(red_X_features, \\\n",
    "                                                    red_target, \\\n",
    "                                                    test_size=red_test_percent/100.0, \\\n",
    "                                                    random_state=10)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "redTree = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "redTree = redTree.fit(X_red_train,y_red_train)\n",
    "\n",
    "#Predict\n",
    "red_prediction = redTree.predict(X_red_test)\n",
    "\n",
    "#How good is this model?\n",
    "metrics.accuracy_score(y_red_test,red_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "Make a prediction with a record from the [red wine data](http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv). Is it accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_x = [\n",
    "    0.0, #'fixed acidity'\n",
    "    0.0, #'volatile acidity'\n",
    "    0.0, #'citric acid' \n",
    "    0.0, #'residual sugar'\n",
    "    0.0, #'chlorides'\n",
    "    0, #'free sulfur dioxide'\n",
    "    0, #'total sulfur dioxide'\n",
    "    0.0, #'density'\n",
    "    0, #'pH'\n",
    "    0, #'sulphates'\n",
    "    1  #'alcohol'\n",
    "]\n",
    "\n",
    "red_x = pd.DataFrame([red_x],columns=X_red_test.columns)\n",
    "redTree.predict_proba(red_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes and Scores\n",
    "\n",
    "Let's just take a look at our data size and how good our models are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#white wine data\n",
    "print(\"\")\n",
    "print(\"White Wine Data\")\n",
    "print(\"Records \",len(white_wine))\n",
    "print(\"Accuracy \",metrics.accuracy_score(y_white_test,white_prediction))\n",
    "\n",
    "#red wine data\n",
    "print(\"\")\n",
    "print(\"Red Wine Data\")\n",
    "print(\"Records \",len(red_wine))\n",
    "print(\"Accuracy \",metrics.accuracy_score(y_red_test,red_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
