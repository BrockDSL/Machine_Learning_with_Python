{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DSL_logo](dsl_logo.png)\n",
    "\n",
    "# Introduction to Machine Learning with Python\n",
    "\n",
    "\n",
    "In our [Data Science](https://brockdsl.github.io/Python_2.0_Workshop/) workshop we introduced some concepts by looking at some fictional data about people that got sick with a mysterious illness. In this session we are going to see if we can build a machine learning model to see if we can predict who has the illness based on the answers to some questions. \n",
    "\n",
    "As a further exercise we'll setup two examples that try to guess the quality of wine. I encourage you to try out these examples after class is done.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, a brief recap on Python code\n",
    "\n",
    "The following code should look familiar to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the file into a dataframe using the pandas read_csv function\n",
    "data = pd.read_csv(\"https://brockdsl.github.io/Python_2.0_Workshop/canadian_toy_dataset.csv\")\n",
    "\n",
    "#Tell it what our columns are by passing along a list of that information\n",
    "data.columns = [\"city\",\"gender\",\"age\",\"income\",\"ill\"]\n",
    "\n",
    "print(\"Ill or not?\")\n",
    "print(data.groupby(\"ill\")[\"city\"].count())\n",
    "print(\"\\nTotal records:\", len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Basics\n",
    "\n",
    "Don't let the impressive name fool you. Machine learning is more or less the following steps\n",
    "\n",
    "1. Getting your data and cleaning it up\n",
    "1. Identify what parts of your data are **features**\n",
    "1. Identify what is your **target variable** that you'll guess based on your features\n",
    "1. Split your data in **training and testing sets**\n",
    "1. **Train** your model against the training set\n",
    "1. **Validate** your model against the testing set\n",
    "1. ????\n",
    "1. Profit\n",
    "\n",
    "\n",
    "We are going to use the Python library [scikit-learn](https://scikit-learn.org/stable/) and we are going to be doing a [classification](https://en.wikipedia.org/wiki/Statistical_classification) problem.\n",
    "\n",
    "![classification](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "This is one of the most basic machine learning model you can use. It is considered a [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) method. You create the best [decision tree](https://en.wikipedia.org/wiki/Decision_tree_learning) that you can based on your training data. Here's an example tree that shows your chance of surviving the Titanic disaster. What we are creating is series of question that when answered will put observations into a _bucket_ or in other terms one of the classification options. We also devise a probability associated with an observation falling into that _bucket_.\n",
    "\n",
    "The features are described by the labels, however ``sibsp`` - is the number of spouses or siblings on board.\n",
    "\n",
    "![dtree](https://upload.wikimedia.org/wikipedia/commons/e/eb/Decision_Tree.jpg)\n",
    "\n",
    "\n",
    "So in this tree the most important question to ask first is what is the gender of the person you are considering, then next most important question is age above 9 and a half, followed lastly by, does this person have less than three spouses or siblings on board.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the Libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This should look familar\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "\n",
    "#We'll draw a graph later on\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Our 'Machine Learning pieces'\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_text\n",
    "from sklearn import metrics \n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data ready\n",
    "\n",
    "Now, let's load our data. Our decision tree can only work with numerical values, so we'll have to modify the columns of data that are text based. As stated preparing the data is usually the most difficult part of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://brockdsl.github.io/Python_2.0_Workshop/canadian_toy_dataset.csv\")\n",
    "data.columns = [\"city\",\"gender\",\"age\",\"income\",\"ill\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is fairly clean, we just need to represent it all as numbers instead of text labels. So that means we need to change the columns:\n",
    "\n",
    "\n",
    "- `ill` - instead of a No / Yes label we'll use 0 and 2 instead\n",
    "- `city` - this will break out the column into 8 different columns\n",
    "- `gender` - this will break out the column into 2 different columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Instead of yes/no we'll use a 0 or 2\n",
    "#We use the value '2' to make our analysis later on less ambiguous\n",
    "data[\"ill\"].replace({\"No\":0, \"Yes\":2},inplace=True)\n",
    "\n",
    "#We change categorical values into numeric ones using `dummies`\n",
    "data = pd.get_dummies(data, columns=['city','gender'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above shows 5 entries that that come from Montreal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows the last 5 entries in the dataframe that come from Edmonton. \n",
    "\n",
    "\n",
    "Now we are done the most difficult part of the process, understanding the data and getting it ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our data cleaned up, and represented in a way that Scikit will be able to analyze. To be honest the most difficult part of the process is done.\n",
    "\n",
    "We now need to split our columns in two types:\n",
    "- **features** represent the data we use to build our guess\n",
    "- **target variable** the thing our model hopes to guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of the following columns are features, we'll make a list of their names\n",
    "features = [\"age\",\\\n",
    "            \"income\",\\\n",
    "            \"city_Edmonton\",\\\n",
    "            \"city_Halifax\",\\\n",
    "            \"city_Montreal\",\n",
    "            \"city_Ottawa\",\\\n",
    "            \"city_Regina\",\\\n",
    "            \"city_Toronto\",\n",
    "            \"city_Vancouver\",\\\n",
    "            \"city_Waterloo\",\\\n",
    "            \"gender_Female\",\\\n",
    "            \"gender_Male\"]\n",
    "\n",
    "X = data[features]\n",
    "\n",
    "#We want to target the ill column\n",
    "y = data.ill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training and testing\n",
    "\n",
    "Now that we have built our model we need to get the data ready for it. We do this by breaking it into two different pieces. The diagram shows a conceptualization of how this is proportioned.\n",
    "\n",
    "![Train Test Split](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/train_test.png)\n",
    "\n",
    "- **Training set** this is what is used to build the model\n",
    "- **Testing set** this is used to see if our guesses are correct\n",
    "\n",
    "Before we were looking at the **columns** of the data, this investigation of training/testing looks at the **rows** of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and test together make up 100% of the data!\n",
    "#We start with a baseline of 30% of our data as testing\n",
    "\n",
    "test_percent = 30\n",
    "train_percent = 100 - test_percent\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0,\n",
    "                                                   random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the interesting part, we build our model, **train** it against the **training set** and see how it **predicts** against the **testing set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "treeClass = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "treeClass = treeClass.fit(X_train,y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = treeClass.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the Model\n",
    "\n",
    "To see how good our machine learning model is we need to see how accurate our predictions are. `Scikit` has built in functions and [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) to do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \")\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Making Predictions\n",
    "\n",
    "Not bad. We can use our model to predict a guess for **ill** if we pass along all of the other parameters. Our model only tells us if someone is ill or not. This is directly asking our classification model to give us a prediction based on a pretend record.\n",
    "\n",
    "Since this classifier tells us if someone is ill or someone is not ill, it has two outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ill.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I randomly picked a record in the dataset to test if the prediction is correct. \n",
    "# This is from line: 149120 of the datafile\n",
    "person_x_yes = [\n",
    "        32, #age\n",
    "        82311, #income\n",
    "        1, #city_Edmonton\n",
    "        0, #city_Halifax\n",
    "        0, #city_Montreal\n",
    "        0, #city_Ottawa\n",
    "        0, #city_Regina\n",
    "        0, #city_Toronto\n",
    "        0, #city_Vancouver\n",
    "        0, #city_Waterloo\n",
    "        0, #gender_Female\n",
    "        1, #gender_Male\n",
    "]\n",
    "\n",
    "person_x_yes = pd.DataFrame([person_x_yes],columns=X_test.columns)\n",
    "\n",
    "print(\"Someone who is ill\")\n",
    "print(\"Class predicted by model: \")\n",
    "print(treeClass.predict(person_x_yes))\n",
    "print(\"Probablity associated with the guess: \")\n",
    "print(treeClass.predict_proba(person_x_yes))\n",
    "\n",
    "\n",
    "\n",
    "# I randomly picked a record in the dataset to test if the prediction is correct. \n",
    "# This is from line: 149121 of the datafile\n",
    "person_x_no = [\n",
    "        40, #age\n",
    "        89780, #income\n",
    "        1, #city_Edmonton\n",
    "        0, #city_Halifax\n",
    "        0, #city_Montreal\n",
    "        0, #city_Ottawa\n",
    "        0, #city_Regina\n",
    "        0, #city_Toronto\n",
    "        0, #city_Vancouver\n",
    "        0, #city_Waterloo\n",
    "        1, #gender_Female\n",
    "        0, #gender_Male\n",
    "]\n",
    "\n",
    "#Use the dataframe of our fictional person in our model and get our prediction\n",
    "person_x_no = pd.DataFrame([person_x_no],columns=X_test.columns)\n",
    "\n",
    "print(\"\\nSomeone who was not ill\")\n",
    "print(\"Class predicted by model: \")\n",
    "print(treeClass.predict(person_x_no))\n",
    "print(\"Probablity associated with the guess: \")\n",
    "print(treeClass.predict_proba(person_x_no))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model constucted we can make ask it question so to speak. We can provide it with details about a pretend person and see what classification the model will place this person.\n",
    "\n",
    "## Q1 - Making a prediction with our model\n",
    "\n",
    "Try to set some parameters in the `pretend_person` variable below to make the prediction determine that the person is **ill**. If you can find one please copy and paste it into the chat box for others to try. You can do this by:\n",
    "- changing the values **line 2 & line 3** for age and income\n",
    "- pick one line from **line 4 to line 11** and change a single row to a value of 1\n",
    "- pick one line from **line 12 to line 13** and change a single row to a value of 1\n",
    "\n",
    "When you are done experiementing please type \"Done\" in the chat box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretend_person = pd.DataFrame([\n",
    "        30, #age - FILL IN\n",
    "        5000, #income - FILL IN\n",
    "        1, #city_Edmonton - ONLY 1 city at a time\n",
    "        0, #city_Halifax\n",
    "        0, #city_Montreal\n",
    "        0, #city_Ottawa\n",
    "        0, #city_Regina\n",
    "        0, #city_Toronto\n",
    "        0, #city_Vancouver\n",
    "        0, #city_Waterloo\n",
    "        1, #gender_Female - ONLY 1 gender at a time\n",
    "        0, #gender_Male\n",
    "])\n",
    "\n",
    "\n",
    "#turn our pretend person into a dataframe that is the correct dimensions\n",
    "pretend_person = pretend_person.T \n",
    "pretend_person.columns = X_test.columns\n",
    "\n",
    "print(\"\\Pretend person details\")\n",
    "print(pretend_person.head())\n",
    "\n",
    "print(\"Pretend person Class predicted\")\n",
    "print(treeClass.predict(pretend_person))\n",
    "\n",
    "print(\"Pretend person probablity of guess\")\n",
    "print(treeClass.predict_proba(pretend_person))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualizing our Decision Tree\n",
    "\n",
    "We can 'visualize' the decision tree to trace through the decisions it makes. In this case we can tell that **income level** is the most important factor that we consider since we ask so many questions about that before looking at any of the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_tree = export_text(treeClass,feature_names=features)\n",
    "print(printed_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters - Testing Set Sizes\n",
    "\n",
    "To make our models run better we can tweak _many, many, many_ different parameters. For example, we can vary the testing data size percentage. We'll try some different values and plot our our accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testing_percents = [1,5,10,20,30,100]\n",
    "accuracy = []\n",
    "training_percents = []\n",
    "\n",
    "for test_ratio in testing_percents:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0,\n",
    "                                                        random_state=10)\n",
    "    treeClassTest = DecisionTreeClassifier()\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    training_percents.append(100 - test_ratio)\n",
    "\n",
    "    \n",
    "plt.plot(training_percents,accuracy)\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Training Size %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your graph might look different, this is a statistical operation and will probably vary across different machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Parameters - Maximum depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 70\n",
    "max_options = [5,10,15,20,25,30]\n",
    "\n",
    "accuracy = []\n",
    "tree_max = []\n",
    "\n",
    "for max_d in max_options:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0,\n",
    "                                                        random_state=10,\n",
    "                                                       )\n",
    "    \n",
    "    #We set maximum depth in the DecisionTreeClassifer when we first create the variable\n",
    "    treeClassTest = DecisionTreeClassifier(max_depth=max_d)\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    tree_max.append(max_d)\n",
    "\n",
    "    \n",
    "plt.plot(max_options,accuracy)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth of Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "\n",
    "We are going to look at a [cancer survivor data set](http://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival) from the UCI machine learning archive.\n",
    "\n",
    "![cancer_description](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/cancer_characteristics.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cancer_data = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data\",header=None)\n",
    "cancer_data.columns = [\"age\",\"operation_year\",\"positive_nodes\",\"survival_status\"]\n",
    "cancer_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Setting up our model\n",
    "\n",
    "- What should our features list look like?\n",
    "- What should or target column be\n",
    "\n",
    "You need to do two things:\n",
    "1. uncomment one line between **line 3 & line 7**\n",
    "2. uncomment one line between **line 13 & line 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What features list should we use, uncomment the correct answer\n",
    "\n",
    "#cancer_features = [\"age\",\"operation_year\",\"positive_nodes\",\"survival_status\"]\n",
    "#cancer_features = [\"age\",\"operation_year\",\"positive_nodes\"]\n",
    "#cancer_features = [\"age\",\"operation_year\"]\n",
    "#cancer_features = [\"age\"]\n",
    "#cancer_features = [\"operation_year\",\"positive_nodes\",\"survival_status\"]\n",
    "\n",
    "\n",
    "#What target should we use, uncomment the correct answer\n",
    "\n",
    "#cancer_target = cancer_data.age\n",
    "#cancer_target = cancer_data.operation_year\n",
    "#cancer_target = cancer_data.positive_nodes\n",
    "#cancer_target = cancer_data.survival_status\n",
    "\n",
    "X = cancer_data[cancer_features]\n",
    "y = cancer_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Continued\n",
    "\n",
    "Now that you have your features and target set, run the next cell to build and test your model.\n",
    "\n",
    "Once you are done type \"finished\" in the chatbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll start with 40 just for fun\n",
    "test_percent = 40\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0,\n",
    "                                                   random_state=10)\n",
    "# Create Decision Tree classifer object\n",
    "treeClass = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "treeClass = treeClass.fit(X_train,y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = treeClass.predict(X_test)\n",
    "\n",
    "#Accuracy\n",
    "print(\"Accuracy:\")\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the tree\n",
    "\n",
    "Now that we have a tree built for this scenario let's display it to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_tree = export_text(treeClass,feature_names=cancer_features)\n",
    "print(printed_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 - Tuning the testing set size\n",
    "\n",
    "Experiment with adding some values in the `testing_percents_cancer` list on **line 3**. \n",
    "\n",
    "In the chat box put in the testing set size that produced the best results.\n",
    "\n",
    "When you are done experiementing type \"Done!\" in the chat box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# put in some values between 0 - 99\n",
    "# add at least 4 values in between the commas\n",
    "testing_percents_cancer = [,,,]\n",
    "\n",
    "#Let's make sure the numbers are all increasing so our graph looks good\n",
    "testing_percents_cancer = sorted(testing_percents_cancer)\n",
    "\n",
    "accuracy = []\n",
    "training_percents = []\n",
    "\n",
    "for test_ratio in testing_percents_cancer:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0,\n",
    "                                                        random_state=10)\n",
    "    treeClassTest = DecisionTreeClassifier()\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    training_percents.append(100 - test_ratio)\n",
    "\n",
    "    \n",
    "plt.plot(training_percents,accuracy)\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Training Size %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 - Turning Parameters, Maximum Tree Depth\n",
    "\n",
    "\n",
    "Experiment with adding some values in the `max_options_cancer` list on **line 5**. \n",
    "\n",
    "In the chat box put in the testing set size that produced the best results.\n",
    "\n",
    "When you are done experiementing type \"Done!\" in the chat box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 30\n",
    "\n",
    "#Put in some options between 1 and 40\n",
    "#add at least 4 values between the commas\n",
    "max_options_cancer = [,,,]\n",
    "\n",
    "#Let's make sure the numbers are all increasing so our graph looks good\n",
    "max_options_cancer = sorted(max_options_cancer)\n",
    "\n",
    "accuracy = []\n",
    "tree_max = []\n",
    "\n",
    "for max_d in max_options_cancer:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                        y, \\\n",
    "                                                        test_size=test_percent/100.0,\n",
    "                                                        random_state=10,\n",
    "                                                       )\n",
    "    \n",
    "    #We set maximum depth in the DecisionTreeClassifer when we first create the variable\n",
    "    treeClassTest = DecisionTreeClassifier(max_depth=max_d)\n",
    "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
    "    y_pred = treeClassTest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    tree_max.append(max_d)\n",
    "\n",
    "    \n",
    "plt.plot(max_options_cancer,accuracy)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth of Tree\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 - Maximizing Accuracy\n",
    "\n",
    "- What is the best combination of `max_depth` and `testing size` that produced the *highest* accuracy?\n",
    "- What is the worst combination of `max_depth` and `testing size` that produced the *lowest* acccuracy? \n",
    "\n",
    "You just need to add some values to **line 3** & **line 4**.\n",
    "\n",
    "Share your answers in the chat.\n",
    "\n",
    "You can experiment using the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Change the following values\n",
    "test_percent = \n",
    "max_tree_depth = \n",
    "\n",
    "#HINT: You can use the previous graphs to help you pick your values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
    "                                                    y, \\\n",
    "                                                    test_size=test_percent/100.0,\n",
    "                                                   random_state=10)\n",
    "# Create Decision Tree classifer object\n",
    "treeClass = DecisionTreeClassifier(max_depth=max_tree_depth)\n",
    "\n",
    "# Train\n",
    "treeClass = treeClass.fit(X_train,y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = treeClass.predict(X_test)\n",
    "\n",
    "#Accuracy?\n",
    "print(\"\\nAccuracy of our tree: \")\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "#Display our final tree\n",
    "print(\"\\nBest tree found:\\n\")\n",
    "printed_tree = export_text(treeClass,feature_names=cancer_features)\n",
    "print(printed_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats!\n",
    "\n",
    "We have just scratched the surface with what is possible with Python and SciKit. Remember, don't let the name **Machine Learning** fool you. Most of the time the computer is making guesses based on past data. Sometimes this works good, sometimes it doesn't work so good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- [UCI Machine Learning Archive](http://archive.ics.uci.edu/ml) A place to find good data sets that you can use to build models with\n",
    "\n",
    "- [A Gentle Introduction to Scikit-Learn](https://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/)\n",
    "\n",
    "- [Data Science Handbook by Field Cady](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119092919)\n",
    "\n",
    "- [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) - A bit more complex, but is a good next step\n",
    "\n",
    "- [Kaggle](https://kagge.com) - A great website with lots of tutorials and data sets to learn and experiment with\n",
    "- [Python for Librarians](https://libraryjuiceacademy.com/shop/course/270-python-for-librarians/) - A 4 week course that I teach that explores Python, data science, and machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Post Workshop Exercises\n",
    "\n",
    "\n",
    "We'll now try to apply what we know about decision trees. We are going to use a dataset from the [UCI machine learning archive](http://archive.ics.uci.edu/ml/datasets/Wine+Quality). We'll start with the white wine data. This screen capture shows the details of the columns of the data:\n",
    "\n",
    "![wine_columns](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/wine_columns.png)\n",
    "\n",
    "We want to create a classification that guesses the quality of the wine based on the first 11 chemical characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_wine = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",sep=';')\n",
    "white_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features should be in our model? What should our target be? Let's look at our dataframe columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Let's fill in the `white_wine_features` list variable below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in this list\n",
    "white_wine_features = []\n",
    "\n",
    "white_X_features = white_wine[white_wine_features]\n",
    "white_X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 \n",
    "\n",
    "In the chat box describe what our **target** should be.\n",
    "Complete the assignment for `white_target` below once you have an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're looking for the column name\n",
    "white_target = white_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "Try to come up with a good testing percentage size. Share it with everyone else after you've measured your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "white_test_percent = \n",
    "\n",
    "#Split into training testing\n",
    "X_white_train, X_white_test, y_white_train, y_white_test = train_test_split(white_X_features, \\\n",
    "                                                    white_target, \\\n",
    "                                                    test_size=white_test_percent/100.0,\n",
    "                                                   random_state=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!!** You have done the most difficult part of a machine learning task. Understanding the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model and get our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "whiteTree = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "whiteTree = whiteTree.fit(X_white_train,y_white_train)\n",
    "\n",
    "#Predict\n",
    "white_prediction = whiteTree.predict(X_white_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how accurate we are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_white_test,white_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some predictions with this tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From line 1408, 8.2;0.22;0.36;6.8;0.034;12;90;0.9944;3.01;0.38;10.5;8\n",
    "white_x_good = [\n",
    "    8.2, #'fixed acidity'\n",
    "    0.22, #'volatile acidity'\n",
    "    0.36, #'citric acid' \n",
    "    6.8, #'residual sugar'\n",
    "    0.034, #'chlorides'\n",
    "    12, #'free sulfur dioxide'\n",
    "    100, #'total sulfur dioxide'\n",
    "    0.0, #'density'\n",
    "    0.9944, #'pH'\n",
    "    0.038, #'sulphates'\n",
    "    10.5  #'alcohol'\n",
    "]\n",
    "\n",
    "white_x_good = pd.DataFrame([white_x_good],columns=X_white_test.columns)\n",
    "whiteTree.predict_proba(white_x_good)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "The above answer is a list with only 7 options, yet our wine score is from 0-10. Can you come up with why that is the case. Feel free to write you answer in the chat box. \n",
    "\n",
    "If you need a hint, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(white_wine[\"quality\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "One more time!\n",
    "\n",
    "(If we have time together we'll try this, if not please give it a shot on your own) Let's try the red wine data, does the classification work better? What is the best score you can get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",sep=';')\n",
    "red_wine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the next 3 variables and the model will run correctly\n",
    "\n",
    "#Create this list, this will be the same as with the white wine\n",
    "red_features = []\n",
    "\n",
    "#What column do we want to target, this will be the same as with the white wine\n",
    "red_target = red_wine.\n",
    "\n",
    "#What is a good testing percentage\n",
    "red_test_percent =\n",
    "\n",
    "\n",
    "#Build and run our model...\n",
    "red_X_features = red_wine[red_features]\n",
    "\n",
    "#Split into training testing\n",
    "X_red_train, X_red_test, y_red_train, y_red_test = train_test_split(red_X_features, \\\n",
    "                                                    red_target, \\\n",
    "                                                    test_size=red_test_percent/100.0, \\\n",
    "                                                    random_state=10)\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "redTree = DecisionTreeClassifier()\n",
    "\n",
    "# Train\n",
    "redTree = redTree.fit(X_red_train,y_red_train)\n",
    "\n",
    "#Predict\n",
    "red_prediction = redTree.predict(X_red_test)\n",
    "\n",
    "#How good is this model?\n",
    "metrics.accuracy_score(y_red_test,red_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "Make a prediction with a record from the [red wine data](http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv). Is it accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_x = [\n",
    "    0.0, #'fixed acidity'\n",
    "    0.0, #'volatile acidity'\n",
    "    0.0, #'citric acid' \n",
    "    0.0, #'residual sugar'\n",
    "    0.0, #'chlorides'\n",
    "    0, #'free sulfur dioxide'\n",
    "    0, #'total sulfur dioxide'\n",
    "    0.0, #'density'\n",
    "    0, #'pH'\n",
    "    0, #'sulphates'\n",
    "    1  #'alcohol'\n",
    "]\n",
    "\n",
    "red_x = pd.DataFrame([red_x],columns=X_red_test.columns)\n",
    "redTree.predict_proba(red_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes and Scores\n",
    "\n",
    "Let's just take a look at our data size and how good our models are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#white wine data\n",
    "print(\"\")\n",
    "print(\"White Wine Data\")\n",
    "print(\"Records \",len(white_wine))\n",
    "print(\"Accuracy \",metrics.accuracy_score(y_white_test,white_prediction))\n",
    "\n",
    "#red wine data\n",
    "print(\"\")\n",
    "print(\"Red Wine Data\")\n",
    "print(\"Records \",len(red_wine))\n",
    "print(\"Accuracy \",metrics.accuracy_score(y_red_test,red_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
